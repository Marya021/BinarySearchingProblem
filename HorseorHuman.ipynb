{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HorseorHuman.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Marya021/BinarySearchingProblem/blob/Marya/HorseorHuman.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tQ3NS4s0EfQS",
        "outputId": "9322aef1-6d4a-4ca2-e925-639a2e72621e"
      },
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip \\\n",
        "    -O /tmp/horse-or-human.zip"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2021-04-15 15:10:52--  https://storage.googleapis.com/laurencemoroney-blog.appspot.com/horse-or-human.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 64.233.170.128, 108.177.13.128, 74.125.26.128, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|64.233.170.128|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149574867 (143M) [application/zip]\n",
            "Saving to: ‘/tmp/horse-or-human.zip’\n",
            "\n",
            "/tmp/horse-or-human 100%[===================>] 142.65M   131MB/s    in 1.1s    \n",
            "\n",
            "2021-04-15 15:10:53 (131 MB/s) - ‘/tmp/horse-or-human.zip’ saved [149574867/149574867]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UQzQZLn_EmWQ"
      },
      "source": [
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/horse-or-human.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp/horse-or-human')\n",
        "zip_ref.close()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oPFpe8ObFyFb"
      },
      "source": [
        "# Directory with our training horse pictures\n",
        "train_horse_dir = os.path.join('/tmp/horse-or-human/horses')\n",
        "\n",
        "# Directory with our training human pictures\n",
        "train_human_dir = os.path.join('/tmp/horse-or-human/humans')"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NzGAcc3-Kw8N"
      },
      "source": [
        "Disini kita akan mengetahui jumlah total gambar kuda dan gambar manusia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HRqqEURIGPuy",
        "outputId": "740028d8-2bc1-4f92-9fe4-93bf5c2ffb06"
      },
      "source": [
        "print('total training horse images:', len(os.listdir(train_horse_dir)))\n",
        "print('total training human images:', len(os.listdir(train_human_dir)))"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total training horse images: 500\n",
            "total training human images: 527\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VwQC36DmMs-Z"
      },
      "source": [
        "Disii kita akan lihat beberapa gambar untuk mendapatkan gambaran yang lebih baik tentan tampilannya"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NGlEaLceLGfv"
      },
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "# Parameters for our graph; we'll output images in a 4x4 configuration\n",
        "nrows = 4\n",
        "ncols = 4\n",
        "\n",
        "# Index for iterating over images\n",
        "pic_index = 0"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "g8JhWws9NCn7"
      },
      "source": [
        "Coba tampilkan 8 gambar kuda dan 8 gambar manusia"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "V_qMR2n6LgNi",
        "outputId": "670b1aa9-f88f-421c-f72a-4941c6cbf61b"
      },
      "source": [
        "# Set up matplotlib fig, and size it to fit 4x4 pics\n",
        "fig = plt.gcf()\n",
        "fig.set_size_inches(ncols * 4, nrows * 4)\n",
        "\n",
        "pic_index += 8\n",
        "next_horse_pix = [os.path.join(train_horse_dir, fname) \n",
        "                for fname in train_horse_names[pic_index-8:pic_index]]\n",
        "next_human_pix = [os.path.join(train_human_dir, fname) \n",
        "                for fname in train_human_names[pic_index-8:pic_index]]\n",
        "\n",
        "for i, img_path in enumerate(next_horse_pix+next_human_pix):\n",
        "  # Set up subplot; subplot indices start at 1\n",
        "  sp = plt.subplot(nrows, ncols, i + 1)\n",
        "  sp.axis('Off') # Don't show axes (or gridlines)\n",
        "\n",
        "  img = mpimg.imread(img_path)\n",
        "  plt.imshow(img)\n",
        "\n",
        "plt.show()\n"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-6-a7b423d351f2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mpic_index\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m next_horse_pix = [os.path.join(train_horse_dir, fname) \n\u001b[0;32m----> 7\u001b[0;31m                 for fname in train_horse_names[pic_index-8:pic_index]]\n\u001b[0m\u001b[1;32m      8\u001b[0m next_human_pix = [os.path.join(train_human_dir, fname) \n\u001b[1;32m      9\u001b[0m                 for fname in train_human_names[pic_index-8:pic_index]]\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_horse_names' is not defined"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1152x1152 with 0 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "B2euAWF8PZ56"
      },
      "source": [
        "Membangun Model Kecil dari Awal"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hcT8ZG_4PjgZ"
      },
      "source": [
        "import tensorflow as tf\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U-eCLEdCPod3"
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n",
        "    # This is the first convolution\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(300, 300, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    # The second convolution\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The third convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fourth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # The fifth convolution\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2,2),\n",
        "    # Flatten the results to feed into a DNN\n",
        "    tf.keras.layers.Flatten(),\n",
        "    # 512 neuron hidden layer\n",
        "    tf.keras.layers.Dense(512, activation='relu'),\n",
        "    # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n",
        "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
        "])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e_2JskoDQIpp"
      },
      "source": [
        "Pemanggilan metode model.summary()dengan mencetak NN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oI42ggk9QOtI",
        "outputId": "c5b0b83b-b900-4df6-959d-8e800724cb69"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 298, 298, 16)      448       \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 149, 149, 16)      0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 147, 147, 32)      4640      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 73, 73, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 71, 71, 64)        18496     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 35, 35, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 33, 33, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 16, 16, 64)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 14, 14, 64)        36928     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_4 (MaxPooling2 (None, 7, 7, 64)          0         \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 3136)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 512)               1606144   \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 513       \n",
            "=================================================================\n",
            "Total params: 1,704,097\n",
            "Trainable params: 1,704,097\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X7nyUkDkQE4C"
      },
      "source": [
        "from tensorflow.keras.optimizers import RMSprop\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=RMSprop(lr=0.001), metrics=['accuracy'])"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G1wJ2QZWQ9e5"
      },
      "source": [
        "# **Data Preprocessing**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e0GKUGZoXvXI"
      },
      "source": [
        "Di Keras ini dapat dilakukan melalui keras.preprocessing.image.ImageDataGeneratorkelas menggunakan rescaleparameter. ImageDataGeneratorKelas ini memungkinkan Anda untuk membuat contoh generator kumpulan gambar yang diperbesar (dan labelnya) melalui .flow(data, labels)atau .flow_from_directory(directory). Generator ini kemudian dapat digunakan dengan metode Model Keras yang menerima generator data input: fit, evaluate_generator, dan predict_generator."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vqw4mZ3zQ8hu",
        "outputId": "15f9fd8e-13ef-43fb-8c9f-25342df029a5"
      },
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# Semua gambar akan diskalakan ulang dengan 1./255\n",
        "train_datagen = ImageDataGenerator(rescale=1/255)\n",
        "\n",
        "# Alirkan gambar pelatihan dalam batch 128 menggunakan generator \n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        '/tmp/horse-or-human/',  # Ini adalah direktori sumber untuk\n",
        "        target_size=(300, 300),  # Semua gambar akan diubah ukurannya menjadi 15\n",
        "        batch_size=128,\n",
        "        # Karena kita menggunakan kerugian binary_crossentropy, kita akan membutuhkan label\n",
        "        class_mode='binary')"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 1027 images belonging to 2 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OGtIPUZFZZbL"
      },
      "source": [
        "# **Latihan**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AW5h_Fp0Z45I",
        "outputId": "02dcaa7d-b108-44eb-9602-7499b7ce4e47"
      },
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch=8,\n",
        "    epochs=15,\n",
        "    verbose=1\n",
        ")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8/8 [==============================] - 73s 9s/step - loss: 0.5092 - accuracy: 0.8603\n",
            "Epoch 4/15\n",
            "8/8 [==============================] - 72s 9s/step - loss: 0.6063 - accuracy: 0.7422\n",
            "Epoch 5/15\n",
            "1/8 [==>...........................] - ETA: 1:21 - loss: 0.2101 - accuracy: 0.9062"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A0BzQnxfaKH4"
      },
      "source": [
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        " \n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(300, 300))\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]>0.5:\n",
        "    print(fn + \" is a human\")\n",
        "  else:\n",
        "    print(fn + \" is a horse\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7br9XTRdGYx"
      },
      "source": [
        "# **Memvisualisasikan Representasikan Menengah**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJTo3c-ZdQKn"
      },
      "source": [
        "Disini kita akan keluarannya menjadi sebuah lapisan, dan setiap gambar di baris adalah filter khusus di peta fitur keluaran. Jalankan kembali sel ini untuk menghasilkan representasi perantara untuk berbagai gambar latihan"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wXt1Mly1c03E"
      },
      "source": [
        "import nupy as np\n",
        "import random\n",
        "from tensorflow.keras.preprocessing.image import img_to_array, load_img"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VhUxphsXd0TY"
      },
      "source": [
        "# Mari kita tentukan model baru yang akan mengambil gambar sebagai masukan dan output\n",
        "# Representasikan menengah untuk semua lapisan di model sebelumnya dan setelahnya\n",
        "succesive_oututs=[layer.output for layer in model.layer[1:]]\n",
        "# Visualization_model = Model(img_input, _outputs berurutan)\n",
        "visualization_model = tf.keras.models.Model (input = model.input, outputs = successive_outputs)\n",
        "# Lalu siapkan gambar input acak dari set pelatihan\n",
        "horse_img_files = [os.path.join(train_horse_dir, f) for f in train_horse_names]\n",
        "human_img_files = [os.path.join(train_human_dir, f) for f in train_human_names]\n",
        "img_path = random.choice(horse_img_files + human_img_files)\n",
        "\n",
        "img = load_img(img_path, target_size=(300, 300))  # this is a PIL image\n",
        "x = img_to_array(img)  # Numpy array with shape (150, 150, 3)\n",
        "x = x.reshape((1,) + x.shape)  # Numpy array with shape (1, 150, 150, 3)\n",
        "\n",
        "# Rescale by 1/255\n",
        "x /= 255\n",
        "\n",
        "# Let's run our image through our network, thus obtaining all\n",
        "# intermediate representations for this image.\n",
        "successive_feature_maps = visualization_model.predict(x)\n",
        "\n",
        "# These are the names of the layers, so can have them as part of our plot\n",
        "layer_names = [layer.name for layer in model.layers[1:]]\n",
        "\n",
        "# Now let's display our representations\n",
        "for layer_name, feature_map in zip(layer_names, successive_feature_maps):\n",
        "  if len(feature_map.shape) == 4:\n",
        "    # Just do this for the conv / maxpool layers, not the fully-connected layers\n",
        "    n_features = feature_map.shape[-1]  # number of features in feature map\n",
        "    # The feature map has shape (1, size, size, n_features)\n",
        "    size = feature_map.shape[1]\n",
        "    # We will tile our images in this matrix\n",
        "    display_grid = np.zeros((size, size * n_features))\n",
        "    for i in range(n_features):\n",
        "      # Postprocess the feature to make it visually palatable\n",
        "      x = feature_map[0, :, :, i]\n",
        "      x -= x.mean()\n",
        "      x /= x.std()\n",
        "      x *= 64\n",
        "      x += 128\n",
        "      x = np.clip(x, 0, 255).astype('uint8')\n",
        "      # We'll tile each filter into this big horizontal grid\n",
        "      display_grid[:, i * size : (i + 1) * size] = x\n",
        "    # Display the grid\n",
        "    scale = 20. / n_features\n",
        "    plt.figure(figsize=(scale * n_features, scale))\n",
        "    plt.title(layer_name)\n",
        "    plt.grid(False)\n",
        "    plt.imshow(display_grid, aspect='auto', cmap='viridis')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wzIT9dvfNIq"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}